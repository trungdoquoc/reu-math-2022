{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpofWgGancyb"
      },
      "source": [
        "The input of the NN is 1D. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "e-NAhHF3ncye"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.functional import normalize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.nn.functional import normalize\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "INPUT_SIZE = 1\n",
        "OUTPUT_SIZE = 1\n",
        "\n",
        "LAMBDA_PEN = 1000000\n",
        "LOWER_BOUND = -6\n",
        "UPPER_BOUND = 6\n",
        "N_POINTS = 1001\n",
        "\n",
        "\n",
        "def quad_fn(a, b, c, x):\n",
        "    return a*x**2 + b*x + c\n",
        "\n",
        "def x_square(x: torch.tensor) -> torch.Tensor:\n",
        "    return x**2\n",
        "\n",
        "# DEFINE GIVEN FUNCTION V(x): ax^2 + bx + c\n",
        "given_fn = x_square"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EstQ_ILqQeOt",
        "outputId": "05fddfe0-6488-47c0-efb9-e701e5b03fea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1001, 1) (1001, 1)\n"
          ]
        }
      ],
      "source": [
        "# CREATING DATASET:\n",
        "x_values = [i for i in np.linspace(LOWER_BOUND, UPPER_BOUND, N_POINTS)]\n",
        "y_values = [given_fn(i) for i in x_values]\n",
        "\n",
        "x_train = np.array(x_values, dtype=np.float32).reshape(-1, 1)\n",
        "y_train = np.array(y_values, dtype=np.float32).reshape(-1, 1)\n",
        "\n",
        "print(x_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "SOtFslmCncyg"
      },
      "outputs": [],
      "source": [
        "# CUSTOM LOSS FUNCTION:\n",
        "# def EpsilonLoss(nn.Module):\n",
        "\n",
        "def epsilon_Loss(v_x, model_u, lower_bound, upper_bound, n_points):\n",
        "    \"\"\"\n",
        "    GOAL: Epsilon function evaluated at u using discretized estimation\n",
        "    minimizing Epsilon(u) = \n",
        "    \n",
        "    ARGS: \n",
        "    n_points (int): number of discretized points on the interval [-L, L]\n",
        "    e.g.: -(L)|---|---|---|---|(L) interval has n_points = 5\n",
        "\n",
        "    v_x (torch.Tensor): function instance\n",
        "    model_u (torch.Tensor): model output\n",
        "    \"\"\"\n",
        "    sum = 0\n",
        "    discrete_points = np.linspace(lower_bound, upper_bound, n_points)\n",
        "    h = discrete_points[1] - discrete_points[0]\n",
        "    for i in discrete_points:\n",
        "        x_i = torch.tensor([i], requires_grad=True, dtype=torch.float)\n",
        "        u_xi = model_u(x_i)\n",
        "\n",
        "        u_prime = model_u.u_prime_2(x_i)\n",
        "        \n",
        "        v_xi = v_x(x_i)\n",
        "        t = torch.square(u_prime) + v_xi*(u_xi**2)\n",
        "        sum += t\n",
        "        # print(\"x_i = \" + str(x_i))\n",
        "        # print(\"u_xi = \" + str(u_xi))\n",
        "        # print(\"u_prime = \" + str(u_prime))\n",
        "        # print(\"v_xi = \" + str(v_xi))\n",
        "        # print(t)\n",
        "        # print('-----')\n",
        "    return 0.5*h*sum\n",
        "\n",
        "def epsilon_Loss_penalty(v_x, model_u, lambda_pen,\n",
        "                         lower_bound, upper_bound, n_points):\n",
        "    \"\"\"\n",
        "    \n",
        "    \"\"\"\n",
        "    sum = 0\n",
        "    pen = 0\n",
        "\n",
        "    discrete_points = np.linspace(lower_bound, upper_bound, n_points)\n",
        "    h = discrete_points[1] - discrete_points[0]\n",
        "    for i in discrete_points:\n",
        "        x_i = torch.tensor([i], requires_grad=True, dtype=torch.float)\n",
        "        u_xi = model_u(x_i)\n",
        "\n",
        "        u_prime = model_u.u_prime_2(x_i)\n",
        "        \n",
        "        v_xi = v_x(x_i)\n",
        "        t = torch.square(u_prime) + v_xi*(u_xi**2)\n",
        "        sum += t\n",
        "    epsilon_fn = 0.5*h*sum\n",
        "    \n",
        "    temp = 0\n",
        "    for i in discrete_points:\n",
        "        x_i = torch.tensor([i], requires_grad=True, dtype=torch.float)\n",
        "        temp += torch.square(model_u(x_i))\n",
        "    \n",
        "    pen = lambda_pen * torch.square((temp*h-1))\n",
        "    return epsilon_fn + pen \n",
        "\n",
        "# NORMALIZE MODEL u(x) OUTPUT:\n",
        "def normalize_u(model_u, lower_bound, upper_bound, n_points):\n",
        "    \"\"\"\n",
        "    Normalize model.output weight by: \n",
        "    model.output *= c\n",
        "    where,\n",
        "    scalar c = 1/denom\n",
        "    \"\"\"\n",
        "    discrete_points = np.linspace(lower_bound, upper_bound, n_points)\n",
        "    h = discrete_points[1] - discrete_points[0]\n",
        "    s = 0\n",
        "    for i in discrete_points:\n",
        "        x_i = torch.tensor([i], requires_grad=True, dtype=torch.float)\n",
        "        t = model_u(x_i)**2\n",
        "        s += t\n",
        "    denom = math.sqrt(h) * torch.sqrt(s)\n",
        "    return 1/denom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "06QWhlkpQ5Eh"
      },
      "outputs": [],
      "source": [
        "# CREATING MODEL CLASS\n",
        "class Nonlinear(nn.Module):\n",
        "    def __init__(self, n):\n",
        "        # One hidden layer with n nodes\n",
        "        super().__init__()\n",
        "        self.hidden = nn.Linear(1, n)\n",
        "        self.output = nn.Linear(n, 1)\n",
        "        \n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.target_fn = given_fn\n",
        "\n",
        "    def forward(self, x, use_tanh_fn = False, activation_on_output = False):\n",
        "        if use_tanh_fn == True:\n",
        "            x = self.hidden(x)\n",
        "            x = self.tanh(x)\n",
        "            x = self.output(x)\n",
        "            \n",
        "        else:\n",
        "            x = self.hidden(x)\n",
        "            x = self.sigmoid(x)\n",
        "            x = self.output(x)\n",
        "            \n",
        "        if activation_on_output == False:\n",
        "            return x\n",
        "        else:\n",
        "            if use_tanh_fn == True:\n",
        "                return self.tanh(x)\n",
        "            else:       \n",
        "                return self.sigmoid(x)\n",
        "        # output is a linear combination of the hidden layers because \n",
        "        # we perform regression ???\n",
        "        return x\n",
        "\n",
        "    def u_prime_2(self, input):\n",
        "        i_clone = input.clone()\n",
        "        clone = copy.deepcopy(self)\n",
        "        res = clone(i_clone).backward()\n",
        "        return i_clone.clone()\n",
        "\n",
        "    def u_prime(self, input):\n",
        "        \"\"\"\n",
        "        NN with 1 hidden node layer is of the form:\n",
        "        u(x) = SUM_i_to_N(a_i * sigmoid(w.x + b))\n",
        "\n",
        "        where\n",
        "        a_i is the corresponding weight of self.output layerq\n",
        "        w is self.hidden.weight vector\n",
        "        b is self.hidden.bias vector\n",
        "        sigmoid(w.x + b) is the sigmoid-activated hidden vector\n",
        "\n",
        "        Formula of u'(x) (for 1 hidden layer NN):\n",
        "        u'(x) = SUM_i_to_N(w_i*a_i*sigmoid'(w_i*x+b))\n",
        "        Note: sigmoid'(w_i*x +b) = sigmoid(w_i*x+b)*(1-sigmoid(w_i*x+b))\n",
        "        \"\"\"\n",
        "        a_i = self.output.weight.data\n",
        "        w_i = torch.transpose(self.hidden.weight.data, 0, 1)\n",
        "        wi_ai = w_i * a_i\n",
        "\n",
        "        hid_layer = self.hidden(input)\n",
        "        hid_layer_T = torch.reshape(hid_layer, (list(hid_layer.shape)[0], 1))\n",
        "        m = hid_layer_T * (1-hid_layer_T)\n",
        "\n",
        "        return wi_ai @ m\n",
        "    \n",
        "# TRANING MODEL\n",
        "    def train_network_with_penalty(self, num_epochs, v_x, optimizer, lambda_pen,\n",
        "                                    lower_bound, upper_bound, n_points):\n",
        "        # For plotting loss value over epochs:\n",
        "        x_epochs = []\n",
        "        y_loss = []\n",
        "        \n",
        "        # stopping criterion:\n",
        "        stop_counter = 0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            optimizer.zero_grad()\n",
        "            loss = epsilon_Loss_penalty(v_x, self, lambda_pen,\n",
        "                                        lower_bound, upper_bound, n_points)\n",
        "            y_loss.append(loss)\n",
        "            x_epochs.append(epoch)\n",
        "            #check if need to stop training:\n",
        "            if epoch > 0 and stop_counter >= 5:\n",
        "                c = normalize_u(self, lower_bound, upper_bound, n_points)\n",
        "                self.output.weight.data.copy_(c.item() * self.output.weight.data)\n",
        "                self.output.bias.data.copy_(c.item() * self.output.bias.data)\n",
        "                print(\"c value = \" + str(c))\n",
        "                print(\"LOSS VALUE = \" \n",
        "                      + str(epsilon_Loss(v_x, self, lower_bound, upper_bound, n_points)))\n",
        "                break\n",
        "            elif epoch > 0 and stop_counter < 5:\n",
        "                if torch.abs(y_loss[epoch-1]-loss) <= 1e-5:\n",
        "                    stop_counter += 1\n",
        "                else:\n",
        "                    stop_counter = 0\n",
        "\n",
        "            print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
        "            loss.backward()\n",
        "            # Calculate the derivative(loss) w.r.t the model's parameters\n",
        "            adam_optimizer.step()\n",
        "\n",
        "        return (x_epochs, y_loss)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = epsilon_Loss(given_fn, model, \n",
        "                            LOWER_BOUND, UPPER_BOUND, N_POINTS)\n",
        "l"
      ],
      "metadata": {
        "id": "2saw960759Td",
        "outputId": "15fd19c7-cccc-403f-dd6f-1b223c54c84d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([78.7160], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "Wgx4K0yugVxX",
        "outputId": "ae40cf07-991b-46ce-e62b-da3c83c7990a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([78.7160], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ],
      "source": [
        "loss = epsilon_Loss_penalty(given_fn, model, LAMBDA_PEN, \n",
        "                            LOWER_BOUND, UPPER_BOUND, N_POINTS)\n",
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "hbBxk8_fncyl"
      },
      "outputs": [],
      "source": [
        "# DEFINE HYPER-PARAMETERS\n",
        "batch_size = 50\n",
        "learningRate = 0.05\n",
        "num_epochs = 2000\n",
        "# num_epochs = int(num_iters/(len(x_train)/batch_size))\n",
        "\n",
        "#INIT PARAMETERS: \n",
        "# v_x = given_fn\n",
        "l_b = -10\n",
        "u_b = 10\n",
        "n_points = 5\n",
        "\n",
        "#INIT MODEL\n",
        "model = Nonlinear(20)\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "\n",
        "# INIT OPTIMIZER CLASS\n",
        "# What is an optimizer: \n",
        "# SGD:\n",
        "# SGD_optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n",
        "# Adam:\n",
        "adam_optimizer = torch.optim.Adam(model.parameters(), \n",
        "                                    lr=learningRate, \n",
        "                                    betas=(0.9, 0.999), \n",
        "                                    eps=1e-08, \n",
        "                                    weight_decay=0, \n",
        "                                    amsgrad=False)\n",
        "\n",
        "# INIT LOSS FUNCTION: MSE\n",
        "# criterion = epsilon_Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZbaJ3MsB08r",
        "outputId": "e4f00711-7d1d-4c9f-f6bf-cb3853261c75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0, loss 311638.4375\n",
            "epoch 1, loss 115870.3203125\n",
            "epoch 2, loss 28678496.0\n",
            "epoch 3, loss 666085.75\n",
            "epoch 4, loss 748461.5625\n",
            "epoch 5, loss 396264.75\n",
            "epoch 6, loss 615118.5625\n",
            "epoch 7, loss 6818436.5\n",
            "epoch 8, loss 10006583.0\n",
            "epoch 9, loss 4798531.5\n",
            "epoch 10, loss 729066.4375\n",
            "epoch 11, loss 16824.146484375\n",
            "epoch 12, loss 447408.21875\n",
            "epoch 13, loss 792369.875\n",
            "epoch 14, loss 821905.5625\n",
            "epoch 15, loss 606870.0625\n",
            "epoch 16, loss 282927.0625\n",
            "epoch 17, loss 31810.541015625\n",
            "epoch 18, loss 64147.80078125\n",
            "epoch 19, loss 477790.15625\n",
            "epoch 20, loss 1043489.8125\n",
            "epoch 21, loss 1290062.25\n",
            "epoch 22, loss 1016130.625\n",
            "epoch 23, loss 505775.9375\n",
            "epoch 24, loss 127561.359375\n",
            "epoch 25, loss 1075.3262939453125\n",
            "epoch 26, loss 51326.9921875\n",
            "epoch 27, loss 170163.625\n",
            "epoch 28, loss 289158.5\n",
            "epoch 29, loss 379963.5\n",
            "epoch 30, loss 436101.375\n",
            "epoch 31, loss 459275.15625\n",
            "epoch 32, loss 452779.40625\n",
            "epoch 33, loss 419435.46875\n",
            "epoch 34, loss 361859.21875\n",
            "epoch 35, loss 283994.6875\n",
            "epoch 36, loss 193340.953125\n",
            "epoch 37, loss 103055.9765625\n",
            "epoch 38, loss 32090.849609375\n",
            "epoch 39, loss 538.6531982421875\n",
            "epoch 40, loss 18684.384765625\n",
            "epoch 41, loss 74616.3828125\n",
            "epoch 42, loss 133458.265625\n",
            "epoch 43, loss 157447.8125\n",
            "epoch 44, loss 133517.9375\n",
            "epoch 45, loss 80612.5703125\n",
            "epoch 46, loss 30292.978515625\n",
            "epoch 47, loss 3382.43994140625\n",
            "epoch 48, loss 2435.376220703125\n",
            "epoch 49, loss 18170.15625\n",
            "epoch 50, loss 38612.359375\n",
            "epoch 51, loss 54529.07421875\n",
            "epoch 52, loss 60977.77734375\n",
            "epoch 53, loss 56923.83984375\n",
            "epoch 54, loss 44384.19140625\n",
            "epoch 55, loss 27550.59375\n",
            "epoch 56, loss 11738.9609375\n",
            "epoch 57, loss 1881.1707763671875\n",
            "epoch 58, loss 652.5919189453125\n",
            "epoch 59, loss 7013.2783203125\n",
            "epoch 60, loss 16378.6044921875\n",
            "epoch 61, loss 22968.978515625\n",
            "epoch 62, loss 23143.2890625\n",
            "epoch 63, loss 17321.8359375\n",
            "epoch 64, loss 9109.205078125\n",
            "epoch 65, loss 2604.377685546875\n",
            "epoch 66, loss 96.84413146972656\n",
            "epoch 67, loss 1442.5223388671875\n",
            "epoch 68, loss 4857.63427734375\n",
            "epoch 69, loss 8167.7734375\n",
            "epoch 70, loss 9779.7109375\n",
            "epoch 71, loss 9131.9541015625\n",
            "epoch 72, loss 6681.29541015625\n",
            "epoch 73, loss 3564.4716796875\n",
            "epoch 74, loss 1070.3973388671875\n",
            "epoch 75, loss 83.45619201660156\n",
            "epoch 76, loss 706.4634399414062\n",
            "epoch 77, loss 2256.524169921875\n",
            "epoch 78, loss 3673.12939453125\n",
            "epoch 79, loss 4121.7890625\n",
            "epoch 80, loss 3424.759521484375\n",
            "epoch 81, loss 2056.851318359375\n",
            "epoch 82, loss 766.6128540039062\n",
            "epoch 83, loss 117.69275665283203\n",
            "epoch 84, loss 235.14370727539062\n",
            "epoch 85, loss 842.834716796875\n",
            "epoch 86, loss 1489.7769775390625\n",
            "epoch 87, loss 1803.11328125\n",
            "epoch 88, loss 1645.7230224609375\n",
            "epoch 89, loss 1135.592529296875\n",
            "epoch 90, loss 547.1404418945312\n",
            "epoch 91, loss 155.077392578125\n",
            "epoch 92, loss 96.84788513183594\n",
            "epoch 93, loss 318.516357421875\n",
            "epoch 94, loss 627.4371337890625\n",
            "epoch 95, loss 815.8125\n",
            "epoch 96, loss 778.6468505859375\n",
            "epoch 97, loss 556.19873046875\n",
            "epoch 98, loss 286.48590087890625\n",
            "epoch 99, loss 109.5962142944336\n",
            "epoch 100, loss 89.25411987304688\n",
            "epoch 101, loss 193.06808471679688\n",
            "epoch 102, loss 329.04412841796875\n",
            "epoch 103, loss 406.5543518066406\n",
            "epoch 104, loss 384.249267578125\n",
            "epoch 105, loss 283.129638671875\n",
            "epoch 106, loss 164.35635375976562\n",
            "epoch 107, loss 89.39186096191406\n",
            "epoch 108, loss 85.84190368652344\n",
            "epoch 109, loss 137.0524444580078\n",
            "epoch 110, loss 198.3414306640625\n",
            "epoch 111, loss 227.25413513183594\n",
            "epoch 112, loss 208.04095458984375\n",
            "epoch 113, loss 156.39410400390625\n",
            "epoch 114, loss 104.61056518554688\n",
            "epoch 115, loss 79.54891204833984\n",
            "epoch 116, loss 87.7288818359375\n",
            "epoch 117, loss 115.34425354003906\n",
            "epoch 118, loss 140.0609130859375\n",
            "epoch 119, loss 145.5714874267578\n",
            "epoch 120, loss 130.03831481933594\n",
            "epoch 121, loss 104.5199203491211\n",
            "epoch 122, loss 84.28312683105469\n",
            "epoch 123, loss 78.95865631103516\n",
            "epoch 124, loss 87.67137145996094\n",
            "epoch 125, loss 101.30867004394531\n",
            "epoch 126, loss 109.45205688476562\n",
            "epoch 127, loss 107.00978088378906\n",
            "epoch 128, loss 96.45169067382812\n",
            "epoch 129, loss 84.9302978515625\n",
            "epoch 130, loss 78.9816665649414\n",
            "epoch 131, loss 80.55968475341797\n",
            "epoch 132, loss 86.64422607421875\n",
            "epoch 133, loss 92.02980041503906\n",
            "epoch 134, loss 92.9328384399414\n",
            "epoch 135, loss 89.13873291015625\n",
            "epoch 136, loss 83.4439468383789\n",
            "epoch 137, loss 79.4265365600586\n",
            "epoch 138, loss 78.97718048095703\n",
            "epoch 139, loss 81.4163818359375\n",
            "epoch 140, loss 84.3599853515625\n",
            "epoch 141, loss 85.54708862304688\n",
            "epoch 142, loss 84.2815170288086\n",
            "epoch 143, loss 81.6240234375\n",
            "epoch 144, loss 79.36741638183594\n",
            "epoch 145, loss 78.73863983154297\n",
            "epoch 146, loss 79.69003295898438\n",
            "epoch 147, loss 81.15990447998047\n",
            "epoch 148, loss 81.94690704345703\n",
            "epoch 149, loss 81.54097747802734\n",
            "epoch 150, loss 80.31842803955078\n",
            "epoch 151, loss 79.14859008789062\n",
            "epoch 152, loss 78.71636962890625\n",
            "epoch 153, loss 79.0971908569336\n",
            "epoch 154, loss 79.81307220458984\n",
            "epoch 155, loss 80.2527847290039\n",
            "epoch 156, loss 80.10916900634766\n",
            "epoch 157, loss 79.53263092041016\n",
            "epoch 158, loss 78.94808959960938\n",
            "epoch 159, loss 78.71629333496094\n",
            "epoch 160, loss 78.8911361694336\n",
            "epoch 161, loss 79.24128723144531\n",
            "epoch 162, loss 79.45902252197266\n",
            "epoch 163, loss 79.38923645019531\n",
            "epoch 164, loss 79.10730743408203\n",
            "epoch 165, loss 78.82306671142578\n",
            "epoch 166, loss 78.71622467041016\n",
            "epoch 167, loss 78.80944061279297\n",
            "epoch 168, loss 78.98287200927734\n",
            "epoch 169, loss 79.08173370361328\n",
            "epoch 170, loss 79.03544616699219\n",
            "epoch 171, loss 78.89107513427734\n",
            "epoch 172, loss 78.7574462890625\n",
            "epoch 173, loss 78.7172622680664\n",
            "epoch 174, loss 78.77293395996094\n",
            "epoch 175, loss 78.85826110839844\n",
            "epoch 176, loss 78.89753723144531\n",
            "epoch 177, loss 78.86360168457031\n",
            "epoch 178, loss 78.78814697265625\n",
            "epoch 179, loss 78.72855377197266\n",
            "epoch 180, loss 78.71910858154297\n",
            "epoch 181, loss 78.75322723388672\n",
            "epoch 182, loss 78.79335021972656\n",
            "epoch 183, loss 78.80538940429688\n",
            "epoch 184, loss 78.78130340576172\n",
            "epoch 185, loss 78.74297332763672\n",
            "epoch 186, loss 78.71835327148438\n",
            "epoch 187, loss 78.72086334228516\n",
            "epoch 188, loss 78.74122619628906\n",
            "epoch 189, loss 78.75859832763672\n",
            "epoch 190, loss 78.75855255126953\n",
            "epoch 191, loss 78.74263000488281\n",
            "epoch 192, loss 78.72409057617188\n",
            "epoch 193, loss 78.7161636352539\n",
            "epoch 194, loss 78.72138214111328\n",
            "epoch 195, loss 78.73253631591797\n",
            "epoch 196, loss 78.73848724365234\n",
            "epoch 197, loss 78.7352523803711\n",
            "epoch 198, loss 78.72561645507812\n",
            "epoch 199, loss 78.7177505493164\n",
            "epoch 200, loss 78.7165756225586\n",
            "epoch 201, loss 78.72099304199219\n",
            "epoch 202, loss 78.72633361816406\n",
            "epoch 203, loss 78.72735595703125\n",
            "epoch 204, loss 78.72361755371094\n",
            "epoch 205, loss 78.71880340576172\n",
            "epoch 206, loss 78.71620178222656\n",
            "epoch 207, loss 78.71719360351562\n",
            "epoch 208, loss 78.71997833251953\n",
            "epoch 209, loss 78.72173309326172\n",
            "epoch 210, loss 78.72100067138672\n",
            "epoch 211, loss 78.71868133544922\n",
            "epoch 212, loss 78.71656036376953\n",
            "epoch 213, loss 78.71622467041016\n",
            "epoch 214, loss 78.7173843383789\n",
            "epoch 215, loss 78.71874237060547\n",
            "epoch 216, loss 78.71898651123047\n",
            "epoch 217, loss 78.71805572509766\n",
            "epoch 218, loss 78.71674346923828\n",
            "epoch 219, loss 78.71612548828125\n",
            "epoch 220, loss 78.7164306640625\n",
            "epoch 221, loss 78.71720886230469\n",
            "epoch 222, loss 78.71759033203125\n",
            "epoch 223, loss 78.71736145019531\n",
            "epoch 224, loss 78.71666717529297\n",
            "epoch 225, loss 78.71615600585938\n",
            "epoch 226, loss 78.7161865234375\n",
            "epoch 227, loss 78.71652221679688\n",
            "epoch 228, loss 78.71685028076172\n",
            "epoch 229, loss 78.71684265136719\n",
            "epoch 230, loss 78.71652221679688\n",
            "epoch 231, loss 78.7161865234375\n",
            "epoch 232, loss 78.71609497070312\n",
            "epoch 233, loss 78.71624755859375\n",
            "epoch 234, loss 78.71643829345703\n",
            "epoch 235, loss 78.71646881103516\n",
            "epoch 236, loss 78.7163314819336\n",
            "epoch 237, loss 78.71615600585938\n",
            "epoch 238, loss 78.7160873413086\n",
            "epoch 239, loss 78.71613311767578\n",
            "epoch 240, loss 78.71623229980469\n",
            "epoch 241, loss 78.71627807617188\n",
            "epoch 242, loss 78.7162094116211\n",
            "epoch 243, loss 78.71612548828125\n",
            "epoch 244, loss 78.71607208251953\n",
            "epoch 245, loss 78.71607208251953\n",
            "epoch 246, loss 78.71614837646484\n",
            "epoch 247, loss 78.71617889404297\n",
            "epoch 248, loss 78.71614837646484\n",
            "epoch 249, loss 78.71607971191406\n",
            "epoch 250, loss 78.716064453125\n",
            "epoch 251, loss 78.71605682373047\n",
            "epoch 252, loss 78.7160873413086\n",
            "epoch 253, loss 78.7160873413086\n",
            "epoch 254, loss 78.71609497070312\n",
            "epoch 255, loss 78.716064453125\n",
            "epoch 256, loss 78.7160415649414\n",
            "epoch 257, loss 78.71604919433594\n",
            "epoch 258, loss 78.716064453125\n",
            "epoch 259, loss 78.716064453125\n",
            "epoch 260, loss 78.71607208251953\n",
            "epoch 261, loss 78.71605682373047\n",
            "epoch 262, loss 78.71603393554688\n",
            "epoch 263, loss 78.71601104736328\n",
            "epoch 264, loss 78.71602630615234\n",
            "epoch 265, loss 78.71601867675781\n",
            "epoch 266, loss 78.71601867675781\n",
            "epoch 267, loss 78.71602630615234\n",
            "epoch 268, loss 78.71601104736328\n",
            "epoch 269, loss 78.71601867675781\n",
            "epoch 270, loss 78.71601104736328\n",
            "epoch 271, loss 78.71600341796875\n",
            "epoch 272, loss 78.71600341796875\n",
            "epoch 273, loss 78.71600341796875\n",
            "c value = tensor([1.0000], grad_fn=<MulBackward0>)\n",
            "LOSS VALUE = tensor([78.7160], grad_fn=<MulBackward0>)\n"
          ]
        }
      ],
      "source": [
        "graph_val = model.train_network_with_penalty(num_epochs, given_fn, adam_optimizer, LAMBDA_PEN, LOWER_BOUND, UPPER_BOUND, N_POINTS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkbD3fXRLGBI",
        "outputId": "7dfa28bb-5379-4069-a4be-cf3dc88e551d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[345.6585]], grad_fn=<MulBackward0>)"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "epsilon_Loss(v_x, model, LOWER_BOUND, UPPER_BOUND, N_POINTS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "XBYQKdIYHYOY"
      },
      "outputs": [],
      "source": [
        "loss_val = [i.detach().numpy().item() for i in graph_val[1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKZP39qEHj_Z",
        "outputId": "065e7dfb-d136-4412-c8e1-70abb86d2b2d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[270, 271, 272, 273, 274]"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "graph_val[0][270:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "jd2I0gRqHO8Z",
        "outputId": "15978184-99da-4f52-d206-d0deff5669aa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_figure(graph_val[0][150:], loss_val[150:])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dear professor, here's my current progress:\n",
        "1. I implement epsilon_Loss_penalty function. Now, the training process will iterate until it counts 5 consecutive times the loss difference between the current loss values with its previous loss < 1e-5. \n",
        "\n",
        "    Then, it finds the normalization constant c and apply to model.output weight layer and its bias. Then the algorithm updates the normalized output weight layer for the model. \n",
        "\n",
        "    The result: the training process only takes < 300 epochs to converge to a loss value of 78.7160. This occurs consistently after several re-runs. The problem: the constant c is 1 from my normalization function. I'm looking for a normalization from the PyTorch library to use instead. Please let me know if I can use this function for the normalization part: [PyTorch normalization function](https://pytorch.org/docs/stable/generated/torch.nn.functional.normalize.html)\n"
      ],
      "metadata": {
        "id": "3GZ9S2gz-JM1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "sjtOBhyZLspO"
      },
      "outputs": [],
      "source": [
        "# PLOT DATA\n",
        "def plot_figure(x_train, y_train, x_test=None, predicted=None):\n",
        "    plt.clf()\n",
        "    plt.figure(figsize=(8, 6), dpi=80)\n",
        "    plt.plot(x_train, y_train, '--', label='True data', alpha=0.5)\n",
        "    if predicted != None:\n",
        "        plt.plot(x_test, predicted, '--', label='Predictions', alpha=0.5)\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "yOAl63W0qaq_",
        "outputId": "0966c5cc-146b-4f15-d330-522a5eafc1e6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plot_figure(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "el6VL83Qddfj"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPn9pDNlm88W"
      },
      "source": [
        "# HOW TO TRAIN THE NN MODEL:\n",
        "1. Reset adam_optimizer: \n",
        "```adam_opt.zero_grad()```\n",
        "2. Calculate loss\n",
        "3. Update the optimizer: \n",
        "```adam_opt.step()```\n",
        "\n",
        "\n",
        "        weight = weight - lr * gradient\n",
        "\n",
        "-> use lr and gradient to \"improve\" weight layer. \n",
        "\n",
        "Explanation:\n",
        "```adam_opt.step()```: Update the model's parameters \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VfCCteSFrC8"
      },
      "outputs": [],
      "source": [
        "model_p = Nonlinear_2(4)\n",
        "adam_opt = torch.optim.Adam(model_p.parameters(), \n",
        "                                    lr=learningRate, \n",
        "                                    betas=(0.9, 0.999), \n",
        "                                    eps=1e-08, \n",
        "                                    weight_decay=0, \n",
        "                                    amsgrad=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUjHqCmkNRzB",
        "outputId": "a8eba8cf-5f24-45cf-f588-85f437d798fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([-0.5799], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "x_i = torch.tensor([-2.5], requires_grad=True, dtype=torch.float)\n",
        "u_xi = model_p(x_i)\n",
        "print(u_xi)\n",
        "u_xi.backward()\n",
        "u_prime = x_i.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0A2qd2M1OXQ5",
        "outputId": "224f75ed-733d-4edc-f3ad-3d78dac7f66a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Hidden layers: \n",
            "Parameter containing:\n",
            "tensor([[-0.4363],\n",
            "        [-0.2556],\n",
            "        [ 0.6323],\n",
            "        [-0.8666]], requires_grad=True)\n",
            "\n",
            "\n",
            "- Hidden layers gradients (derivative of Loss w.r.t model params): \n",
            "None\n",
            "Parameter containing:\n",
            "tensor([ 0.9463, -0.8034, -0.8181,  0.5812], requires_grad=True)\n",
            "\n",
            "\n",
            "Output layers: \n",
            "Parameter containing:\n",
            "tensor([[-0.3294, -0.3360,  0.0453, -0.0283]], requires_grad=True)\n",
            "None\n",
            "Parameter containing:\n",
            "tensor([0.4850], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# Access the model's parameters:\n",
        "# Model's hidden layer weight and bias\n",
        "print(\"- Hidden layers: \")\n",
        "print(model_p.hidden.weight)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"- Hidden layers gradients (derivative of Loss w.r.t model params): \")\n",
        "print(model_p.hidden.weight.grad)\n",
        "print(model_p.hidden.bias)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Model's output layer weight and bias\n",
        "print(\"Output layers: \")\n",
        "print(model_p.output.weight)\n",
        "print(model_p.hidden.weight.grad)\n",
        "print(model_p.output.bias)\n",
        "\n",
        "# model.zero_grad()\n",
        "\n",
        "i, o = (x_train[0], y_train[0])\n",
        "i = Variable(torch.from_numpy(i))\n",
        "o = Variable(torch.from_numpy(o))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "YI4vusv8w_40",
        "outputId": "9797e6a2-cd0f-49fd-db59-c2fda0e16171"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear(in_features=1, out_features=4, bias=True)\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-148-d51b9355ea65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_pp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon_Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgiven_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_pp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOWER_BOUND\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUPPER_BOUND\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_POINTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
          ]
        }
      ],
      "source": [
        "import copy\n",
        "\n",
        "model_pp = copy.deepcopy(model_p)\n",
        "print(model_pp.hidden)\n",
        "loss = epsilon_Loss(given_fn, model_pp, LOWER_BOUND, UPPER_BOUND, N_POINTS)\n",
        "loss.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBY2VlCqSVjE"
      },
      "outputs": [],
      "source": [
        "model_pp.hidden.weight.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "ELHbc3btUq9f",
        "outputId": "1c256f77-a69d-4303-85c0-4c502ab692c8"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-123-52a0569421b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
          ]
        }
      ],
      "source": [
        "loss.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BA_91qCHWhjs",
        "outputId": "20a262ba-f9a2-4cf1-b0c4-110596eb2f63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- Hidden layers: \n",
            "Parameter containing:\n",
            "tensor([[-0.4363],\n",
            "        [-0.2556],\n",
            "        [ 0.6323],\n",
            "        [-0.8666]], requires_grad=True)\n",
            "\n",
            "\n",
            "- Hidden layers gradients (derivative of Loss w.r.t model params): \n",
            "None\n",
            "Parameter containing:\n",
            "tensor([ 0.9463, -0.8034, -0.8181,  0.5812], requires_grad=True)\n",
            "\n",
            "\n",
            "Output layers: \n",
            "Parameter containing:\n",
            "tensor([[-0.3294, -0.3360,  0.0453, -0.0283]], requires_grad=True)\n",
            "None\n",
            "Parameter containing:\n",
            "tensor([0.4850], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print(\"- Hidden layers: \")\n",
        "print(model_p.hidden.weight)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"- Hidden layers gradients (derivative of Loss w.r.t model params): \")\n",
        "print(model_p.hidden.weight.grad)\n",
        "print(model_p.hidden.bias)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Model's output layer weight and bias\n",
        "print(\"Output layers: \")\n",
        "print(model_p.output.weight)\n",
        "print(model_p.hidden.weight.grad)\n",
        "print(model_p.output.bias)\n",
        "\n",
        "# model.zero_grad()\n",
        "\n",
        "i, o = (x_train[0], y_train[0])\n",
        "i = Variable(torch.from_numpy(i))\n",
        "o = Variable(torch.from_numpy(o))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jQeEbaMHkeA",
        "outputId": "32d5985d-7d0f-4048-c555-7ef3785149ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 0., 0.])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.grad.zero_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkmedTJ6J1Hr",
        "outputId": "01a83e6e-280c-4a72-d9c4-bff991258866"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([True, True])\n",
            "tensor([True, True])\n"
          ]
        }
      ],
      "source": [
        "a = torch.tensor([2., 3.], requires_grad=True)\n",
        "b = torch.tensor([6., 4.], requires_grad=True)\n",
        "\n",
        "t = 3*a**3 - b**2\n",
        "\n",
        "external_grad = torch.tensor([1., 1.])\n",
        "t.backward(gradient=external_grad)\n",
        "\n",
        "print(9*a**2 == a.grad)\n",
        "print(-2*b == b.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyuNXuz-iLBZ"
      },
      "source": [
        "https://neptune.ai/blog/pytorch-loss-functions\n",
        "https://stackoverflow.com/questions/53980031/pytorch-custom-loss-function\n",
        "https://stackoverflow.com/questions/65947284/loss-with-custom-backward-function-in-pytorch-exploding-loss-in-simple-mse-exa\n",
        "https://www.youtube.com/watch?v=ma2KXWblllc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0PS0efCiJCp"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "PyTorch_.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "8c21580189d9a9d7f1e3fef63ff70de58083dda94aa35d8ed937f03fa405217e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}