{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpofWgGancyb"
      },
      "source": [
        "The input of the NN is 1D. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e-NAhHF3ncye"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from torch.autograd import Variable\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "INPUT_SIZE = 1\n",
        "OUTPUT_SIZE = 1\n",
        "\n",
        "LOWER_BOUND = -10\n",
        "UPPER_BOUND = 10\n",
        "N_POINTS = 200\n",
        "\n",
        "\n",
        "def quad_fn(a, b, c, x):\n",
        "\treturn a*x**2 + b*x + c\n",
        "\n",
        "def x_square(x: torch.tensor) -> torch.Tensor:\n",
        "\treturn x**2\n",
        "\n",
        "# DEFINE GIVEN FUNCTION V(x): ax^2 + bx + c\n",
        "given_fn = x_square"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EstQ_ILqQeOt",
        "outputId": "ccbcff69-d87b-4610-9801-d49ae734cc57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(200, 1) (200, 1)\n"
          ]
        }
      ],
      "source": [
        "# CREATING DATASET:\n",
        "x_values = [i for i in np.linspace(LOWER_BOUND, UPPER_BOUND, N_POINTS)]\n",
        "y_values = [given_fn(i) for i in x_values]\n",
        "\n",
        "x_train = np.array(x_values, dtype=np.float32).reshape(-1, 1)\n",
        "y_train = np.array(y_values, dtype=np.float32).reshape(-1, 1)\n",
        "\n",
        "print(x_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SOtFslmCncyg"
      },
      "outputs": [],
      "source": [
        "# CUSTOM LOSS FUNCTION:\n",
        "# def EpsilonLoss(nn.Module):\n",
        "\n",
        "def epsilon_Loss(v_x, model_u, lower_bound, upper_bound, n_points):\n",
        "    \"\"\"\n",
        "    GOAL: Epsilon function evaluated at u using discretized estimation\n",
        "    minimizing Epsilon(u) = \n",
        "    \n",
        "    ARGS: \n",
        "    n_points (int): number of discretized points on the interval [-L, L]\n",
        "    e.g.: -(L)|---|---|---|---|(L) interval has n_points = 5\n",
        "\n",
        "    v_x (torch.Tensor): function instance\n",
        "    model_u (torch.Tensor): model output\n",
        "    \"\"\"\n",
        "    sum = 0\n",
        "    discrete_points = np.linspace(lower_bound, upper_bound, n_points)\n",
        "    for i in discrete_points:\n",
        "        x_i = torch.tensor([i], requires_grad=True, dtype=torch.float)\n",
        "        u_xi = model_u(x_i)\n",
        "\n",
        "        # u_xi.backward()\n",
        "        # u_prime = x_i.grad\n",
        "        \n",
        "        u_prime = model_u.u_prime(x_i)\n",
        "        \n",
        "        v_xi = v_x(x_i)\n",
        "        t = torch.abs(u_prime)**2 + v_xi*(u_xi**2)\n",
        "        sum += t\n",
        "        # print(\"x_i = \" + str(x_i))\n",
        "        # print(\"u_xi = \" + str(u_xi))\n",
        "        # print(\"u_prime = \" + str(u_prime))\n",
        "        # print(\"v_xi = \" + str(v_xi))\n",
        "        # print(t)\n",
        "        # print('-----')\n",
        "    return 0.5*sum\n",
        "\n",
        "# NORMALIZE MODEL u(x) OUTPUT:\n",
        "def normalize_u(model_u, lower_bound, upper_bound, n_points):\n",
        "    \"\"\"\n",
        "    Normalize model.output weight by: \n",
        "    model.output *= c\n",
        "    where,\n",
        "    scalar c = 1/denom\n",
        "    \"\"\"\n",
        "    discrete_points = np.linspace(lower_bound, upper_bound, n_points)\n",
        "    h = discrete_points[1] - discrete_points[0]\n",
        "    s = 0\n",
        "    for i in discrete_points:\n",
        "        x_i = torch.tensor([i], requires_grad=True, dtype=torch.float)\n",
        "        t = model_u(x_i)**2\n",
        "        s += t\n",
        "    denom = math.sqrt(h) * torch.sqrt(s)\n",
        "    return 1/denom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "06QWhlkpQ5Eh"
      },
      "outputs": [],
      "source": [
        "# CREATING MODEL CLASS\n",
        "class Nonlinear(nn.Module):\n",
        "    def __init__(self, n):\n",
        "        # One hidden layer with n nodes\n",
        "        super().__init__()\n",
        "        self.hidden = nn.Linear(1, n)\n",
        "        self.output = nn.Linear(n, 1)\n",
        "        \n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.target_fn = given_fn\n",
        "\n",
        "    def forward(self, x, use_tanh_fn = False, activation_on_output = False):\n",
        "        if use_tanh_fn == True:\n",
        "            x = self.hidden(x)\n",
        "            x = self.tanh(x)\n",
        "            x = self.output(x)\n",
        "            \n",
        "        else:\n",
        "            x = self.hidden(x)\n",
        "            x = self.sigmoid(x)\n",
        "            x = self.output(x)\n",
        "            \n",
        "        if activation_on_output == False:\n",
        "            return x\n",
        "        else:\n",
        "            if use_tanh_fn == True:\n",
        "                return self.tanh(x)\n",
        "            else:       \n",
        "                return self.sigmoid(x)\n",
        "        # output is a linear combination of the hidden layers because \n",
        "        # we perform regression ???\n",
        "        return x\n",
        "\n",
        "    def u_prime(self, input):\n",
        "        \"\"\"\n",
        "        NN with 1 hidden node layer is of the form:\n",
        "        u(x) = SUM_i_to_N(a_i * sigmoid(w.x + b))\n",
        "\n",
        "        where\n",
        "        a_i is the corresponding weight of self.output layerq\n",
        "        w is self.hidden.weight vector\n",
        "        b is self.hidden.bias vector\n",
        "        sigmoid(w.x + b) is the sigmoid-activated hidden vector\n",
        "\n",
        "        Formula of u'(x) (for 1 hidden layer NN):\n",
        "        u'(x) = SUM_i_to_N(w_i*a_i*sigmoid'(w_i*x+b))\n",
        "        Note: sigmoid'(w_i*x +b) = sigmoid(w_i*x+b)*(1-sigmoid(w_i*x+b))\n",
        "        \"\"\"\n",
        "        a_i = self.output.weight.data\n",
        "        w_i = torch.transpose(self.hidden.weight.data, 0, 1)\n",
        "        wi_ai = w_i * a_i\n",
        "\n",
        "        hid_layer = self.hidden(input)\n",
        "        hid_layer_T = torch.reshape(hid_layer, (list(hid_layer.shape)[0], 1))\n",
        "        m = hid_layer_T * (1-hid_layer_T)\n",
        "\n",
        "        return wi_ai @ m\n",
        "    \n",
        "# TRANING MODEL\n",
        "    def train_network(self, num_epochs, v_x, optimizer, \n",
        "                      LOWER_BOUND, UPPER_BOUND, N_POINTS):\n",
        "        # For plotting loss value over epochs:\n",
        "        x_epochs = [i for i in range(num_epochs)]\n",
        "        y_loss = []\n",
        "        for epoch in range(num_epochs):\n",
        "            if epoch % 50 == 0:\n",
        "                # normalize model.ouput.weight\n",
        "                # TODO: Do I need to normalize the bias?\n",
        "                c = normalize_u(self, LOWER_BOUND, UPPER_BOUND, N_POINTS)\n",
        "                self.output.weight.data.copy_(c.item() * self.output.weight.data)\n",
        "\n",
        "            for (input, output) in (zip(x_train, y_train)):\n",
        "                # if torch.cuda.is_available():\n",
        "                #     input = Variable(torch.from_numpy(input).cuda())\n",
        "                #     output = Variable(torch.from_numpy(output).cuda())\n",
        "                # else:\n",
        "                input = Variable(torch.from_numpy(input))\n",
        "                output = Variable(torch.from_numpy(output))\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                loss = epsilon_Loss(v_x, self, LOWER_BOUND, \n",
        "                                    UPPER_BOUND, N_POINTS)\n",
        "                # print(model.hidden.weight.grad)\n",
        "                loss.backward()\n",
        "                # loss.backward()\n",
        "                # print(loss.data)\n",
        "                # print(type(loss))\n",
        "                # TODO: calculate the derivative(loss) w.r.t the model's parameters\n",
        "                # TODO: use adam optimizer to update the parameters\n",
        "                adam_optimizer.step()\n",
        "            loss = epsilon_Loss(given_fn, model, LOWER_BOUND, \n",
        "                                    UPPER_BOUND, N_POINTS)\n",
        "            y_loss.append(loss)\n",
        "            print('epoch {}, loss {}'.format(epoch, loss.item()))\n",
        "\n",
        "        return (x_epochs, y_loss)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "r_Y6gCLiLo5Y",
        "outputId": "0f3c4a52-f591-42ba-92fc-cbae6ec32231",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.cuda of Nonlinear(\n",
              "  (hidden): Linear(in_features=1, out_features=5, bias=True)\n",
              "  (output): Linear(in_features=5, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              "  (tanh): Tanh()\n",
              ")>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "hbBxk8_fncyl"
      },
      "outputs": [],
      "source": [
        "# DEFINE HYPER-PARAMETERS\n",
        "batch_size = 50\n",
        "learningRate = 0.05\n",
        "num_epochs = 1000\n",
        "# num_epochs = int(num_iters/(len(x_train)/batch_size))\n",
        "\n",
        "#INIT PARAMETERS: \n",
        "# v_x = given_fn\n",
        "l_b = -10\n",
        "u_b = 10\n",
        "n_points = 5\n",
        "\n",
        "#INIT MODEL\n",
        "model = Nonlinear(5)\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "\n",
        "# INIT OPTIMIZER CLASS\n",
        "# What is an optimizer: \n",
        "# SGD:\n",
        "# SGD_optimizer = torch.optim.SGD(model.parameters(), lr=learningRate)\n",
        "# Adam:\n",
        "adam_optimizer = torch.optim.Adam(model.parameters(), \n",
        "                                    lr=learningRate, \n",
        "                                    betas=(0.9, 0.999), \n",
        "                                    eps=1e-08, \n",
        "                                    weight_decay=0, \n",
        "                                    amsgrad=False)\n",
        "\n",
        "# INIT LOSS FUNCTION: MSE\n",
        "# criterion = epsilon_Loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "graph_val = model.train_network(num_epochs, given_fn, adam_optimizer, LOWER_BOUND, UPPER_BOUND, N_POINTS)"
      ],
      "metadata": {
        "id": "WZbaJ3MsB08r",
        "outputId": "d408636c-7414-4b59-93cf-3cf5c1ce32cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0, loss 366.4354248046875\n",
            "epoch 1, loss 176.8972930908203\n",
            "epoch 2, loss 105.49504852294922\n",
            "epoch 3, loss 80.48761749267578\n",
            "epoch 4, loss 71.78555297851562\n",
            "epoch 5, loss 67.88192749023438\n",
            "epoch 6, loss 64.92372131347656\n",
            "epoch 7, loss 61.9002685546875\n",
            "epoch 8, loss 58.66411209106445\n",
            "epoch 9, loss 55.26643371582031\n",
            "epoch 10, loss 51.75843048095703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_val = [0.1817954182624817, 0.05032005533576012, 0.011522994376718998, 0.002926675835624337, 0.001283779856748879, 0.0009413482039235532, 0.0008131795912049711, 0.000722082972060889, 0.0006411740323528647, 0.0005663186311721802, 0.000497222354169935, 0.000633180548902601, 0.0003815441741608083, 0.00041009296546690166, 0.00027364707784727216, 0.00025978381745517254, 0.27622777223587036, 0.0001702941517578438, 0.01936458609998226, 0.00012408044131007046, 0.004012296907603741, 9.834294178290293e-05, 0.00016300356946885586, 8.257748413598165e-05, 0.00010627388837747276, 0.0006671213777735829, 8.665369387017563e-05, 0.32811009883880615, 5.265657455311157e-05, 0.005848045460879803, 5.156049519428052e-05, 0.007710508070886135, 0.00013975596812088042, 0.0013823237968608737, 0.000212768922210671, 0.0001788920199032873, 7.175825157901272e-05, 9.072926332009956e-05, 2.53463077545166, 1.0930462849501055e-05]"
      ],
      "metadata": {
        "id": "w6YopEIrKkJY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Dear professor, here is the plot for . For now I only "
      ],
      "metadata": {
        "id": "zkbD3fXRLGBI",
        "outputId": "7dfa28bb-5379-4069-a4be-cf3dc88e551d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_val = [i.detach().numpy().item() for i in graph_val[1]]"
      ],
      "metadata": {
        "id": "XBYQKdIYHYOY"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_val"
      ],
      "metadata": {
        "id": "fKZP39qEHj_Z",
        "outputId": "7e932255-337e-431a-b7cb-2b8997aba1d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0653328225016594,\n",
              " 0.058631569147109985,\n",
              " 0.041199956089258194,\n",
              " 0.02013426274061203,\n",
              " 0.006599788554012775,\n",
              " 0.002496907487511635,\n",
              " 0.0021015144884586334,\n",
              " 0.0018891587387770414,\n",
              " 0.001976498868316412,\n",
              " 0.012490830384194851]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_figure([i for i in range(len(loss_val))], loss_val)"
      ],
      "metadata": {
        "id": "jd2I0gRqHO8Z",
        "outputId": "7bfadfbf-2fa3-4ac0-876a-61575a761f7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhkAAAGMCAYAAAB3WbDmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAMTQAADE0B0s6tTgAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAdQklEQVR4nO3df2zc9Z3n8dd7bJRE640d0yRQxq6dJi2FYhygEEWB69FyqHcVykG0LW25UtENCPVEyaUthzhd1Zaqt9UiWu3dgmGXlCK2u7ecoF1xcLQl1+2ytDTEZKgENEccewIkFOME1ISFmff9MWPjhEmYbzLvfL/z9fMhjTI/Pvn4/fHX3/HL3+/n8x1zdwEAALRaIe0CAABAPhEyAABACEIGAAAIQcgAAAAhCBkAACAEIQMAAIQgZAAAgBCdaRcwbd68eb548eK0ywAAAAns2rXrX9x9XqPXMhMyFi9erHK5nHYZAAAgATN7+XCvcboEAACEIGQAAIAQmTldciTValV8xkocM1OhQN4EALRWpkNGtVrVzp07deDAgbRLyb2Ojg4tXrxYixYtSrsUAEBOZDpk7NmzR4VCQStWrJCZpV1Obrm7Dhw4oF27dkkSQQMA0BKZDRnurqmpKQ0MDKizM7Nl5kZXV5dOOeUUvfDCC4QMAEBLZPZEvLvL3XXCCSekXcqcMX/+fFUqFVWr1bRLAQDkQKZDBo6v6VNSfO8BAK2Q2ZBxLNxd43vHNfrSqMb3jrfsl+bw8LCGh4d12mmnqaOjY+bxpz71qZb0/27WrVunTZs2vWu7TZs26ZlnnokvCACAI8jdZIepA1Ma2TKibbu3qcM6VPGKhpYOaf3Z69Uzv+eY+h4dHZUkjY2NaXh4eObxbG+99Vbqc0g2bdqknp4enXrqqanWAQCY23J1JMPdNbJlRKU9JS1btEyDiwY12DOo0p6S7thyR9hpgIGBAX3ta1/Tueeeq89//vPavHmzhoeHZ15/+umnNTAwMPP44Ycf1po1a3T22Wfr3HPP1aOPPtqw32eeeUarV6/W6aefrrVr12rfvn0zr917770677zztHLlSp155pn6yU9+Ikm688479Zvf/EbXX3+9hoeH9eCDD6pUKmnNmjU666yzdNppp+lb3/pWyPcBABAr6kh9lFwdyZjYN6HS7pIGFw2qYLX81FHo0ED3gLbt3qaJfRPq7+4P+dqvvPKKfvWrX8nMtHnz5sO2e/755/X1r39dDz/8sBYuXKjt27fr/PPP19jYmObNO/jzZa644gpdc801uuqqq1QqlXTOOefoM5/5jCTp4osv1uWXXy4z09jYmFatWqWdO3fqi1/8ou655x59+ctf1tq1ayVJr732mn72s59p3rx52r9/v1avXq2Pf/zjWrVqVcj3AgDQepFH6qPkKmRM7p9UwQozAWNaR6FDhUJBk/snw0LGlVde2dS1PB566CFt375dF1xwwcxzhUJB4+PjWrFixcxz+/bt0+joqK688kpJ0hlnnKE1a9bMvL5jxw599rOfVblcVmdnpyYnJ7Vjx46Gp0j279+va6+9VqOjoyoUCpqYmNDo6CghAwDaxKFH6gtWUKVamTlSv3H1xkxeTypXIaN3Qa8qXlHVqwcFjUq1tiyzd0Fv2Nfu6uqaud/Z2alKpTLzePYVS91dF110ke69997EX2P2D9CnP/1pfec739G6deskSb29vYe9MuqNN96o97znPdq6das6Ozt16aWXchVVAGgjaR6pPxa5mpPRt7BPQ0uHtGNqhyrV2i/5SrWisb1jGlo6pL6FfceljmXLlmnnzp16+eXap9/+8Ic/nHnt4osv1k9/+lNt27Zt5rlf//rX7+hj4cKFWrlype6++25J0m9/+1v98pe/nHn91Vdf1eDgoCTpnnvu0auvvnrQ/927d+9BbYvFojo7O/Xss8/qkUceadFIAQDHQzNH6rOoqZBhZvPN7H4ze87MnjKzR8xseYN2A2ZWMbPRWbf3t77sw9ap9Wev1xlLztDY1Jh2TO3Q2NSYhpbUzlkdr0NJ733ve/XVr35V5557rlatWqXe3rePoCxfvlz33nuvrr76ap155pn60Ic+pFtvvbVhP3fffbdGRkb04Q9/WDfddNNBp1i+973vad26dVq5cqW2bt2q/v63E+z69ev17W9/e2bi50033aS77rpLQ0NDuuGGG3ThhRfGDR4A0HKzj9TPdjyO1B8La2ZmqpnNl3ShpP/t7m5mX5K0zt0/eki7AUmj7p54BkqxWPRyuTzzuFKp6LnnntMHPvABdXR0JOrL3TWxb0KT+yfVu6BXfQv7MnmuKmuO5XsOAIjj7vruY99VaU9JA90D6ih0vH2kfslQqnMyzGyXuxcbvdbUnAx3PyDpwVlPPS5pYwtqC2Fm6u/uz+T5KQAAkpo+Uj+yZUSl3SUVCgVVq9WZ1SVZ/UP6aCd+XifpgcO89kdm9oSkDkn3S7rZ3SuHaQsAAJrQM79HX1n9lbY6Up84ZJjZjZKWS/pYg5dflHSKu+8xs15JfyvpP0n6swb9bJC0Yfpxd3d30lIAAJhT2u1IfaLVJWa2UdKlkj7h7n849HV3f8Pd99TvT0r6a0nnN+rL3W9x9+L0bfYS0PrXmm6XpEQcg+nvdZZTMQCgfTR9JKN+5OFySR9396nDtFki6VV3f9PM5qkWSLYeTWGFQkEnnHCCXnnlFZ144on84gv25ptvavfu3Zo/f74KhVytbAYApKSpkGFmRUl/Lul5SY/Wf+G/4e7nmdk3JL3g7rdJWiPpG2ZWqff9c0k3H21x/f39Gh8f1+RkNtf/5omZqaenR0uWLEm7FABATjS1hPV4OHQJ62zVapXTJoHMbOYGAEASx7yENW0cvgcAoP3w2xsAAIQgZAAAgBCEDAAAEIKQAQAAQhAyAABACEIGAAAIQcgAAAAhCBkAACAEIQMAAIQgZAAAgBCEDAAAEIKQAQAAQhAyAABACEIGAAAIQcgAAAAhCBkAACAEIQMAAIQgZAAAgBCEDAAAEIKQAQAAQhAyAABACEIGAAAIQcgAAAAhCBkAACAEIQMAAIQgZAAAgBCEDAAAEIKQAQAAQhAyAABACEIGAAAIQcgAAAAhCBkAACAEIQMAAIQgZAAAgBCEDAAAEIKQAQAAQhAyAABACEIGAAAIQcgAAAAhCBkAACAEIQMAAIQgZAAAgBCEDAAAEIKQAQAAQhAyAABACEIGAAAIQcgAAAAhCBkAACAEIQMAAIQgZAAAgBCEDAAAEIKQAQAAQhAyAABACEIGAAAIQcgAAAAhmgoZZjbfzO43s+fM7Ckze8TMlh+m7SfN7Bkz+52Z/S8zW9jakgEAQDtIciRjRNIH3f1MSQ9IuvPQBmbWJemvJK119xWSXpD0X1pRKAAAaC9NhQx3P+DuD7q71596XNJAg6afkLTV3Z+pP/4fki4/5ioBAEDbOdo5GdepdjTjUP2Sds56PCbpZDPrPMqvAwAA2lTiX/5mdqOk5ZI+dixf2Mw2SNow/bi7u/tYugMAABmT6EiGmW2UdKmkT7j7Hxo0GZf0vlmPByS96O5vHdrQ3W9x9+L0raurK0kpAAAg45oOGfUjD5dLusjdpw7T7CFJZ5nZqfXH10r60bGVCAAA2lFTp0vMrCjpzyU9L+lRM5OkN9z9PDP7hqQX3P02d3/NzL4o6f76PIynJX0+qHYAAJBh9vaCkXQVi0Uvl8tplwEAABIws13uXmz0Glf8BAAAIQgZAAAgBCEDAACEIGQAAIAQhAwAABCCkAEAAEIQMgAAQAhCBgAACEHIAAAAIQgZAAAgBCEDAACEIGQAAIAQhAwAABCCkAEAAEIQMgAAQAhCBgAACEHIAAAAIQgZAAAgBCEDAACEIGQAAIAQhAwAABCCkAEAAEIQMgAAQAhCBgAACEHIAAAAIQgZAAAgBCEDAACEIGQAAIAQhAwAABCCkAEAAEIQMgAAQAhCBgAACEHIAAAAIQgZAAAgBCEDAACEIGQAAIAQhAwAABCCkAEAAEIQMgAAQAhCBgAACEHIAAAAIQgZAAAgBCEDAACEIGQAAIAQhAwAABCCkAEAAEIQMgAAQAhCBgAACEHIAAAAIQgZAAAgBCEDAACEIGQAAIAQhAwAABCCkAEAAEIQMgAAQAhCBgAACNFUyDCz75vZmJm5mQ0fps1HzWy/mY3Oui1obbkAAKBddDbZ7u8l/ZmkX75Lu2fdvWEIAQAAc0tTIcPdfyFJZhZbDQAAyI1Wz8l4v5k9aWZPmNm1Le4bAAC0kWZPlzTjSUlFd99rZkVJD5rZ79397xo1NrMNkjZMP+7u7m5hKQAAIG0tO5Lh7vvcfW/9flnS30g6/wjtb3H34vStq6urVaUAAIAMaFnIMLOTzaxQv//Hkj4paWur+gcAAO2l2SWst5tZWVJR0sNmtr3+/J1mdkm92WWSSmb2lKTHJT0i6a6AmgEAQBswd0+7BklSsVj0crmcdhkAACABM9vl7sVGr3HFTwAAEIKQAQAAQhAyAABACEIGAAAIQcgAAAAhCBkAACAEIQMAAIQgZAAAgBCEDAAAEIKQAQAAQhAyAABACEIGAAAIQcgAAAAhCBkAACAEIQMAAIQgZAAAgBCEDAAAEIKQAQAAQhAyAABACEIGAAAIQcgAAAAhCBkAACAEIQMAAIQgZAAAgBCEDAAAEIKQAQAAQhAyAABACEIGAAAIQcgAAAAhCBkAACAEIQMAAIQgZAAAgBCEDAAAEIKQAQAAQhAyAABACEIGAAAIQcgAAAAhCBkAACAEIQMAAIQgZAAAgBCEDAAAEIKQAQAAQhAyAABACEIGAAAIQcgAAAAhCBkAACAEIQMAAIQgZAAAgBCEDAAAEIKQAQAAQhAyAABACEIGAAAIQcgAAAAhCBkAACAEIQMAAIQgZAAAgBBNhQwz+76ZjZmZm9nwEdpdZWa/M7P/Z2Z3mNkJrSsVAAC0k2aPZPy9pDWSdh6ugZkNSvqmpPMlLZe0VNL6Yy0QAAC0p6ZChrv/wt3L79JsnaQfu/tL7u6SbpN0+bEWCAAA2lMr52T06+AjHWP15wAAwByU2sRPM9tgZuXp2+uvv55WKQAAIEArQ8a4pPfNejxQf64hd7/F3YvTt66urhaWAgAA0tbKkHGfpEvM7CQzM0nXSPpRC/sHAABtpNklrLebWVlSUdLDZra9/vydZnaJJLn785L+q6R/krRd0suSbg+pGgAAZJ7VFoKkr1gsern8bgtYAABAlpjZLncvNnqNK34CAIAQhAwAABCCkAEAAEIQMgAAQAhCBgAACEHIAAAAIQgZAAAgBCEDAACEIGQAAIAQhAwAABCCkAEAAEIQMgAAQAhCBgAACEHIAAAAIQgZAAAgBCEDAACEIGQAAIAQhAwAABCCkAEAAEIQMgAAQAhCBgAACEHIAAAAIQgZAAAgBCEDAACEIGQAAIAQhAwAABCCkAEAAEIQMgAAQAhCBgAACEHIAAAAIQgZAAAgBCEDAACEIGQAAIAQhAwAABCCkAEAAEIQMgAAQAhCBgAACEHIAAAAIQgZAAAgBCEDAACEIGQAAIAQhAwAABCCkAEAAEIQMgAAQAhCBgAACEHIAAAAIQgZAAAgBCEDAACEIGQAAIAQhAwAABCCkAEAAEIQMgAAQAhCBgAACEHIAAAAIQgZAAAgBCEDAACEaDpkmNkKM3vMzJ4zsyfM7PQGbT5qZvvNbHTWbUFrSwYAAO2gM0Hb2yWNuPsmM1snaZOkjzRo96y7D7eiOAAA0L6aOpJhZksknSPpnvpT90nqM7PlUYUBAID21uzpkj5JL7r7W5Lk7i5pXFJ/g7bvN7Mn66dUrm1RnQAAoM0kOV3SjCclFd19r5kVJT1oZr939787tKGZbZC0Yfpxd3d3i0sBAABpavZIxoSkk82sU5LMzFQ7ijE+u5G773P3vfX7ZUl/I+n8Rh26+y3uXpy+dXV1He0YAABABjUVMtx9j2pHKT5Xf+oySWV33z67nZmdbGaF+v0/lvRJSVtbVy4AAGgXSa6TcbWkq83sOUk3SPqCJJnZnWZ2Sb3NZZJKZvaUpMclPSLprhbWCwAA2oTV5nCmr1gserlcTrsMAACQgJntcvdio9e44icAAAhByAAAACEIGQAAIAQhAwAAhCBkAACAEIQMAAAQgpABAABCEDIAAEAIQgYAAAhByAAAACEIGQAAIAQhAwAAhCBkAACAEJ1pFwAASMbdNbFvQpP7J9W7oFd9C/tkZmmXBbwDIQMA2sjUgSmNbBnRtt3b1GEdqnhFQ0uHtP7s9eqZ35N2ecBBOF0CAG3C3TWyZUSlPSUtW7RMg4sGNdgzqNKeku7YcofcPe0SgYMQMgCgTUzsm1Bpd0mDPYMqWO3tu6PQoYHuAW3bvU0T+yZSrhA4GCEDANrE5P5JFawwEzCmdRQ6VCgUNLl/MqXKgMYIGQDQJnoX9KriFVW9etDzlWpF1WpVvQt6U6oMaIyQAQBtom9hn4aWDmnH1A5VqhVJtYAxtndMQ0uH1LewL+UKgYOxugRoUyxjnHvMTOvPXl+b/Lm7pEKhoGq1OrO6hO2PrLGszEYuFoteLpfTLgNoCyxjnNsImMgSM9vl7sWGrxEygPbi7vruY99Vac/bqwxmDpkvGdLG1Rv5hQPguDlSyGBOBtBmWMYIoF0QMoA2wzJGAO2CkAG0GZYxAmgXhAygzbCMEUC7IGQAbWZ6GeMZS87Q2NSYdkzt0NhUbdInyxgBZAmrS4A2xTJGAFlwpNUlXIwLaFNmpv7ufvV396ddCgA0xOkSAAAQgpABAABC5PZ0CeerAQBIVy5DBp/rAABA+nJ3usTda59QuKekZYuWaXDRoAZ7BlXaU9IdW+5QVlbTAACQd7kLGXyuAwAA2ZC7kMHnOgAAkA25Cxl8rgMAANmQu5DB5zoAAJANuQsZfK4DAADZkNvPLuE6GQAAxJuTn13C5zoAAJCu3J0uAQAA2UDIAAAAIQgZAAAgBCEDAACEIGQAAIAQhAwAABCCkAEAAELk9joZSXHxLgAAWouQIWnqwJRGtoxo2+5t6rAOVbyioaW1y5D3zO9JuzwAANrSnD9d4u4a2TKi0p6Sli1apsFFgxrsGVRpT0l3bLlDWbnsOgAA7WbOh4yJfRMq7S5psGdQBat9OzoKHRroHtC23ds0sW8i5QoBAGhPcz5kTO6fVMEKMwFjWkehQ4VCQZP7J1OqDEiPu2t877hGXxrV+N5xjugBOCpzfk5G74JeVbyiqlcPChqVakXValW9C3rf8X+YJIo8Y44SgFaZ8yGjb2GfhpYOqbSnpIHuAXUUOlSpVjS2d0xDS4fUt7DvoPZH8wZMKEG7OHSOUsEKqlQrM3OUNq7eeMw/u+wP2Ra5fdj2c0/TIcPMVkj6gaT3SNor6Up3/22DdldJukG1UzE/l3Stu7/ZmnJbz8y0/uz1tTfW3SUVCgVVq9WZ4DB7BziaN+CkoSTpTpikfWTfWaplrvSdVDP9z8xRWnT4OUr93f1HXXt0SJ8rP+NJZWH7HI8/0LKyfdpx20dJciTjdkkj7r7JzNZJ2iTpI7MbmNmgpG9KOkvSbkkPSFov6b+3pNogPfN79JXVX2n5G3DSUJJ0J0zSPrLvLNUyV/pOqtn+m5mjdGjIaLbv6JA+V37Gk8rC9jkef6BlZfu047aP1NTETzNbIukcSffUn7pPUp+ZLT+k6TpJP3b3l7w2U+w2SZe3qthIZqb+7n4NnzSs/u7+hkkv6STRJCtXki6lTdI+su8s1TJX+k4qSf+z5yjNdrg5Skn6TrqSKyvbJ2u1JJGV7RPZd5a2T7tu+0jNri7pk/Siu78lSfUAMS7p0OOm/ZJ2zno81qBN20r6BpwklCTdCZO0j+w7S7XMlb6TStL/9BylHVM7VKlWJOmIc5SS9B0Z0ufKz3hSWdk+kX0nbd+ufSeVlcszpLaE1cw2mFl5+vb666+nVUrTkr4BJwklSXfCJO0j+85SLXOl76SS9D89R+mMJWdobGpMO6Z2aGxqTENL3jlHKWnfkSF9rvyMJ5WV7RPZd9L27dp3Ulm5PEOzczImJJ1sZp3u/pbV3mn6VTuaMdu4pPfPejzQoI0kyd1vkXTL9ONisZj5hfhJJolKyVauJF1Km6R9ZN9ZqmWu9J1U0v6bnaOUtO+kK7mysn2yVksSWdk+kX0nbd+ufScV/b7SrKaOZLj7HklPSvpc/anLJJXdffshTe+TdImZnVQPItdI+lGris2C6Tfgmz92s65fdb1u/tjN2rh6o7rnd7+jbZK/CpMeJUnSPrLvLNUyV/pO6mj6b2aOUtK+kx4lycr2yVotSWRl+0T2nbR9u/adVPT7SrOs2ckfZvZB1VaUnChpn6QvuHvJzO5UbbLnj+vt/lS1JayStFnSNc0sYS0Wi14ulxMPoB0kXeLV6ChJoxCTpH1k31mqZa70nVRk/0n7TrKkLivbJ2u1JJGV7RPdd1a2Tztv+6NlZrvcvdjwtaxcLjjPISOJdl67nZVa5krfSbXrWvysbJ+s1ZLEXOk7K9tnrmz7aYQMAAAQ4kghY85/QBoAAIhByAAAACEIGQAAIAQhAwAAhCBkAACAEIQMAAAQgpABAABCEDIAAEAIQgYAAAhByAAAACEyc1lxM3tD0ssBXXdJej2g36xhnPkxF8YoMc68YZz5kmSci919XqMXMhMyophZ+XDXVM8Txpkfc2GMEuPMG8aZL60aJ6dLAABACEIGAAAIMRdCxi1pF3CcMM78mAtjlBhn3jDOfGnJOHM/JwMAAKRjLhzJAAAAKSBkAACAELkNGWa2wsweM7PnzOwJMzs97ZoimNmYmT1rZqP126fSrqkVzOz79bG5mQ3Pej5X2/UI48zNdjWz+WZ2f32bPWVmj5jZ8vprS8zsITP7nZk9bWYXpF3v0XqXcW42sx2ztuf1add7LMzs/5jZtvpY/tHMVtafz9v+ebhx5mb/nGZmX6i/D62tP27NvunuubxJ+rmkK+v310l6Iu2agsY5Jmk47ToCxnWBpOKh48vbdj3COHOzXSXNl/Rv9fYcsC9J2ly//9eSvl6//xFJZUknpF1zwDg3S1qbdo0tHGvPrPv/XtJT9ft52z8PN87c7J/18QxIekzSP0//nLZq38zlkQwzWyLpHEn31J+6T1Lf9F8VyD53/4W7l2c/l8ft2miceePuB9z9Qa+/W0l6XLU3NUn6E0m31ds9IekFSf/quBfZAu8yzlxx96lZD7sleU73z3eMM61aophZQdKdkv6jpDdmvdSSfTOXIUNSn6QX3f0tSarv9OOS+lOtKs7dZlYys78ys8VpFxOI7ZoP10l6wMxOVO0vo5dmvTam/GzP6yQ9MOvxd+rb82/NbFlaRbWKmd1tZhOSvinpCuV0/2wwzml52T83SPond98y/UQr9828hoy55AJ3H5J0lqTfS/pByvWgNXK5Xc3sRknLJf3ntGuJ1GCcV7j7qZKGJP2jpH9Iq7ZWcff/4O59km6S9N/SrifKYcaZi/3TzD4s6TJJ34r6GnkNGROSTjazTkkyM1MtgY2nWlUAdx+v//umpFslnZ9uRaHYrm3MzDZKulTSJ9z9D+7+iqS3zOykWc0G1Obb89BxSpK7T9T/dXf/C0nL6n8ttj13/4Gkf63aOfvc7p/T4zSzE3O0f56v2j73OzMbk7RK0ohqp0pasm/mMmS4+x5JT0r6XP2pyySV3X17elW1npn9kZn1zHrqcklb06onGtu1fZnZBtXGcdEh57n/p6Rr6m0+IukUSf/3+FfYGo3GaWadZrZ0VpvLJO2uh6y2Y2Y9ZvbeWY/XSnpFUq72zyOM80Be9k93/0t3P9ndB9x9QLV5ROvd/S/Von0zt1f8NLMPStok6URJ+yR9wd1LqRbVYvXzuvdJ6pBkkp6XdJ27j6VZVyuY2e2S/p2kk1TbsV9z9+V5266Nxinp3yhH29XMiqodhXpetfFJ0hvufl79l+8PJQ1K+hdJX3L3R9Op9NgcbpySLlTtzXmepKpqh9c3uPtTadR5rMzsfar9Alqg2nhelrTR3UfztH8ebpyqjSs3++dsZrZZ0q3ufn+r9s3chgwAAJCuXJ4uAQAA6SNkAACAEIQMAAAQgpABAABCEDIAAEAIQgYAAAhByAAAACEIGQAAIAQhAwAAhPj/+Z2xoZYFwrEAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v_x = given_fn\n",
        "l_b = -10\n",
        "u_b = 10\n",
        "n_points = 200\n",
        "model_u = Nonlinear(20)\n",
        "\n",
        "res = epsilon_Loss(given_fn, model_u, l_b, u_b, n_points)\n",
        "print(res)"
      ],
      "metadata": {
        "id": "cCkoJj5T_zJp",
        "outputId": "3e9c3ed2-6155-4032-d183-d635d1285ff1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[642.3246]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6LvtISYK8FUi",
        "outputId": "4c246612-ab4c-48ae-b9ee-0418513326c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[642.3246]], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = model_u.output.weight.data\n",
        "c = normalize_u(model_u, LOWER_BOUND, UPPER_BOUND, N_POINTS)\n",
        "print(w)\n"
      ],
      "metadata": {
        "id": "f3H_OYsD3Ris",
        "outputId": "2f57d2dc-1a04-40d3-c00a-4d963360b105",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1041,  0.0962, -0.1771,  0.0874,  0.1113, -0.2226, -0.1965, -0.0349,\n",
            "         -0.1274, -0.0800, -0.1009, -0.0265,  0.1447, -0.1653, -0.0199,  0.1231,\n",
            "         -0.1137, -0.0332,  0.1343, -0.2128]])\n",
            "tensor([[ 0.0539,  0.0498, -0.0917,  0.0452,  0.0576, -0.1152, -0.1017, -0.0180,\n",
            "         -0.0659, -0.0414, -0.0522, -0.0137,  0.0749, -0.0855, -0.0103,  0.0637,\n",
            "         -0.0589, -0.0172,  0.0695, -0.1101]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_u.output.weight.data.copy_(c.item() * w)\n",
        "print(model_u.output.weight.data)\n",
        "#= model_u.output.weight * c.item()"
      ],
      "metadata": {
        "id": "1UZQFTMv48md",
        "outputId": "5491fa81-deee-465c-ca24-3bd104b7e8bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0539,  0.0498, -0.0917,  0.0452,  0.0576, -0.1152, -0.1017, -0.0180,\n",
            "         -0.0659, -0.0414, -0.0522, -0.0137,  0.0749, -0.0855, -0.0103,  0.0637,\n",
            "         -0.0589, -0.0172,  0.0695, -0.1101]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_u.output.weight.data"
      ],
      "metadata": {
        "id": "1S4oHY3zAek7",
        "outputId": "722cad77-2e93-4063-823e-220240245b5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0539,  0.0498, -0.0917,  0.0452,  0.0576, -0.1152, -0.1017, -0.0180,\n",
              "         -0.0659, -0.0414, -0.0522, -0.0137,  0.0749, -0.0855, -0.0103,  0.0637,\n",
              "         -0.0589, -0.0172,  0.0695, -0.1101]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6dekwy_ncyl",
        "outputId": "906bac5c-4024-4fcc-953c-99187704bafa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-f12cb4c8bd04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0madam_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon_Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgiven_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOWER_BOUND\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUPPER_BOUND\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_POINTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m# print(model.hidden.weight.grad)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-80-c1e88f9d35a1>\u001b[0m in \u001b[0;36mepsilon_Loss\u001b[0;34m(v_x, model_u, lower_bound, upper_bound, n_points)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mu_prime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mu_prime_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_u\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mu_prime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_prime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_prime_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-81-8c5cc755c418>\u001b[0m in \u001b[0;36mu_prime\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mwi_ai\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw_i\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma_i\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mhid_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_u\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mhid_layer_T\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhid_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhid_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhid_layer_T\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mhid_layer_T\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not numpy.float64"
          ]
        }
      ],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "sjtOBhyZLspO"
      },
      "outputs": [],
      "source": [
        "# PLOT DATA\n",
        "def plot_figure(x_train, y_train, x_test=None, predicted=None):\n",
        "    plt.clf()\n",
        "    plt.figure(figsize=(8, 6), dpi=80)\n",
        "    plt.plot(x_train, y_train, 'go', label='True data', alpha=0.5)\n",
        "    if predicted != None:\n",
        "        plt.plot(x_test, predicted, '--', label='Predictions', alpha=0.5)\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_figure(x_train, y_train)"
      ],
      "metadata": {
        "id": "yOAl63W0qaq_",
        "outputId": "270473f0-e4e2-48b8-88af-be4bd72bf19b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "el6VL83Qddfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HOW TO TRAIN THE NN MODEL:\n",
        "1. Reset adam_optimizer: \n",
        "```adam_opt.zero_grad()```\n",
        "2. Calculate loss\n",
        "3. Update the optimizer: \n",
        "```adam_opt.step()```\n",
        "\n",
        "\n",
        "        weight = weight - lr * gradient\n",
        "\n",
        "-> use lr and gradient to \"improve\" weight layer. \n",
        "\n",
        "Explanation:\n",
        "```adam_opt.step()```: Update the model's parameters \n"
      ],
      "metadata": {
        "id": "VPn9pDNlm88W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_p = Nonlinear_2(4)\n",
        "adam_opt = torch.optim.Adam(model_p.parameters(), \n",
        "                                    lr=learningRate, \n",
        "                                    betas=(0.9, 0.999), \n",
        "                                    eps=1e-08, \n",
        "                                    weight_decay=0, \n",
        "                                    amsgrad=False)"
      ],
      "metadata": {
        "id": "0VfCCteSFrC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_i = torch.tensor([-2.5], requires_grad=True, dtype=torch.float)\n",
        "u_xi = model_p(x_i)\n",
        "print(u_xi)\n",
        "u_xi.backward()\n",
        "u_prime = x_i.grad"
      ],
      "metadata": {
        "id": "MUjHqCmkNRzB",
        "outputId": "a8eba8cf-5f24-45cf-f588-85f437d798fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.5799], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the model's parameters:\n",
        "# Model's hidden layer weight and bias\n",
        "print(\"- Hidden layers: \")\n",
        "print(model_p.hidden.weight)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"- Hidden layers gradients (derivative of Loss w.r.t model params): \")\n",
        "print(model_p.hidden.weight.grad)\n",
        "print(model_p.hidden.bias)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Model's output layer weight and bias\n",
        "print(\"Output layers: \")\n",
        "print(model_p.output.weight)\n",
        "print(model_p.hidden.weight.grad)\n",
        "print(model_p.output.bias)\n",
        "\n",
        "# model.zero_grad()\n",
        "\n",
        "i, o = (x_train[0], y_train[0])\n",
        "i = Variable(torch.from_numpy(i))\n",
        "o = Variable(torch.from_numpy(o))\n"
      ],
      "metadata": {
        "id": "0A2qd2M1OXQ5",
        "outputId": "224f75ed-733d-4edc-f3ad-3d78dac7f66a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Hidden layers: \n",
            "Parameter containing:\n",
            "tensor([[-0.4363],\n",
            "        [-0.2556],\n",
            "        [ 0.6323],\n",
            "        [-0.8666]], requires_grad=True)\n",
            "\n",
            "\n",
            "- Hidden layers gradients (derivative of Loss w.r.t model params): \n",
            "None\n",
            "Parameter containing:\n",
            "tensor([ 0.9463, -0.8034, -0.8181,  0.5812], requires_grad=True)\n",
            "\n",
            "\n",
            "Output layers: \n",
            "Parameter containing:\n",
            "tensor([[-0.3294, -0.3360,  0.0453, -0.0283]], requires_grad=True)\n",
            "None\n",
            "Parameter containing:\n",
            "tensor([0.4850], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "model_pp = copy.deepcopy(model_p)\n",
        "print(model_pp.hidden)\n",
        "loss = epsilon_Loss(given_fn, model_pp, LOWER_BOUND, UPPER_BOUND, N_POINTS)\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "YI4vusv8w_40",
        "outputId": "9797e6a2-cd0f-49fd-db59-c2fda0e16171",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=1, out_features=4, bias=True)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-148-d51b9355ea65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_pp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepsilon_Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgiven_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_pp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLOWER_BOUND\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUPPER_BOUND\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_POINTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_pp.hidden.weight.grad"
      ],
      "metadata": {
        "id": "OBY2VlCqSVjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()"
      ],
      "metadata": {
        "id": "ELHbc3btUq9f",
        "outputId": "1c256f77-a69d-4303-85c0-4c502ab692c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-123-52a0569421b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"- Hidden layers: \")\n",
        "print(model_p.hidden.weight)\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"- Hidden layers gradients (derivative of Loss w.r.t model params): \")\n",
        "print(model_p.hidden.weight.grad)\n",
        "print(model_p.hidden.bias)\n",
        "print(\"\\n\")\n",
        "\n",
        "# Model's output layer weight and bias\n",
        "print(\"Output layers: \")\n",
        "print(model_p.output.weight)\n",
        "print(model_p.hidden.weight.grad)\n",
        "print(model_p.output.bias)\n",
        "\n",
        "# model.zero_grad()\n",
        "\n",
        "i, o = (x_train[0], y_train[0])\n",
        "i = Variable(torch.from_numpy(i))\n",
        "o = Variable(torch.from_numpy(o))"
      ],
      "metadata": {
        "id": "BA_91qCHWhjs",
        "outputId": "20a262ba-f9a2-4cf1-b0c4-110596eb2f63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Hidden layers: \n",
            "Parameter containing:\n",
            "tensor([[-0.4363],\n",
            "        [-0.2556],\n",
            "        [ 0.6323],\n",
            "        [-0.8666]], requires_grad=True)\n",
            "\n",
            "\n",
            "- Hidden layers gradients (derivative of Loss w.r.t model params): \n",
            "None\n",
            "Parameter containing:\n",
            "tensor([ 0.9463, -0.8034, -0.8181,  0.5812], requires_grad=True)\n",
            "\n",
            "\n",
            "Output layers: \n",
            "Parameter containing:\n",
            "tensor([[-0.3294, -0.3360,  0.0453, -0.0283]], requires_grad=True)\n",
            "None\n",
            "Parameter containing:\n",
            "tensor([0.4850], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad.zero_()"
      ],
      "metadata": {
        "id": "6jQeEbaMHkeA",
        "outputId": "32d5985d-7d0f-4048-c555-7ef3785149ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([2., 3.], requires_grad=True)\n",
        "b = torch.tensor([6., 4.], requires_grad=True)\n",
        "\n",
        "t = 3*a**3 - b**2\n",
        "\n",
        "external_grad = torch.tensor([1., 1.])\n",
        "t.backward(gradient=external_grad)\n",
        "\n",
        "print(9*a**2 == a.grad)\n",
        "print(-2*b == b.grad)"
      ],
      "metadata": {
        "id": "zkmedTJ6J1Hr",
        "outputId": "01a83e6e-280c-4a72-d9c4-bff991258866",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([True, True])\n",
            "tensor([True, True])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://neptune.ai/blog/pytorch-loss-functions\n",
        "https://stackoverflow.com/questions/53980031/pytorch-custom-loss-function\n",
        "https://stackoverflow.com/questions/65947284/loss-with-custom-backward-function-in-pytorch-exploding-loss-in-simple-mse-exa\n",
        "https://www.youtube.com/watch?v=ma2KXWblllc"
      ],
      "metadata": {
        "id": "ZyuNXuz-iLBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "M0PS0efCiJCp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.7 ('venv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "8c21580189d9a9d7f1e3fef63ff70de58083dda94aa35d8ed937f03fa405217e"
      }
    },
    "colab": {
      "name": "PyTorch_.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}